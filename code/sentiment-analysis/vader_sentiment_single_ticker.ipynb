{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "dir_name = '../../database_real/sentiment_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Description\n",
      "Symbol                                 \n",
      "1            Cheung Kong (Holdings) Ltd\n",
      "2                      CLP Holdings Ltd\n",
      "3       Hong Kong and China Gas Co. Ltd\n",
      "4                  Wharf (Holdings) Ltd\n",
      "5                     HSBC Holdings plc\n"
     ]
    }
   ],
   "source": [
    "# get data for hkex equity stock\n",
    "hkex_files = os.path.join(dir_name,'stock_ticker_datasets/hkex_in.csv')\n",
    "\n",
    "hkex = pd.read_csv(hkex_files)\n",
    "\n",
    "hkex['Symbol'] = hkex['Symbol'].astype(str)\n",
    "hkex_input = hkex['Symbol']\n",
    "\n",
    "n = 400  #chunk row size\n",
    "hkex_df = [hkex_input[i:i+n] for i in range(0,hkex_input.shape[0],n)]\n",
    "\n",
    "hkex.set_index(\"Symbol\" , inplace=True)\n",
    "print(hkex.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import twitter_samples \n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the compound vader score to the corresponding news\n",
    "def read_news_path(df):\n",
    "    print('read in datasets')\n",
    "    cs=[]\n",
    "    # append a compound score to every news row\n",
    "    for row in range(len(df)):\n",
    "        cs.append(analyser.polarity_scores(df['news'].iloc[row])['compound'])\n",
    "    # append the column to original dataset\n",
    "    df['compound_vader_score']=cs\n",
    "    return df\n",
    "\n",
    "\n",
    "# group by the mean compound vader score by dates\n",
    "def find_news_pred_label(df,threshold):\n",
    "    print('find_pred_label')\n",
    "    news = df['news']\n",
    "    # group the data by dates\n",
    "    df = df.groupby(['dates'])['compound_vader_score'].mean().reset_index()\n",
    "    final_label=[]\n",
    "    \n",
    "    # convert the vader score using a threshold to a sentiment label\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        if df['compound_vader_score'].iloc[i] > threshold:\n",
    "            final_label.append(2)\n",
    "        elif df['compound_vader_score'].iloc[i] < -threshold:\n",
    "            final_label.append(0)\n",
    "        elif (df['compound_vader_score'].iloc[i] >= -threshold  \n",
    "              and df['compound_vader_score'].iloc[i] <= threshold):\n",
    "            final_label.append(1)\n",
    "\n",
    "    df['vader_label'] = final_label\n",
    "    return df\n",
    "\n",
    "\n",
    "# merge the dataset with the hang seng index daily moving average\n",
    "def merge_actual_label (df,hsi_movement_df):\n",
    "    print('merge_actual_label')\n",
    "    vader_data = df\n",
    "    vader_data.set_index(keys = [\"dates\"],inplace=True)\n",
    "    label_data = pd.read_csv(hsi_movement_df)\n",
    "    label_data.set_index(keys = [\"dates\"],inplace=True)\n",
    "    # inner join the two datasets using the date index\n",
    "    merge = pd.merge(vader_data,label_data, how='inner', left_index=True, right_index=True)\n",
    "    merge = merge.reset_index()\n",
    "    # drop the redudant column \n",
    "    merge = merge.drop(['Unnamed: 0'],axis=1)\n",
    "    \n",
    "    return merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'hkex_df' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-677c3f10b708>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# collect vader label for tickers in hkex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtickers\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhkex_df\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m      \u001b[0;32mfor\u001b[0m \u001b[0mticker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtickers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hkex_df' is not defined"
     ]
    }
   ],
   "source": [
    "def starter_vader(ticker):\n",
    "    # get the full path of each ticker\n",
    "    path = os.path.join(dir_name,'data-news/data-aastock/'+'data-'+ticker.zfill(5)+'-aastock.csv')           \n",
    "    df = pd.read_csv(path,names=['dates','news','ticker','newstype'])\n",
    "    # read append the compound vader score to the pandas dataframe\n",
    "    df = read_news_path(df)\n",
    "    # pass in the threshold to get the vader label\n",
    "    df = find_news_pred_label(df,0.01)\n",
    "            \n",
    "    result_path = os.path.join(dir_name,'data-results/vader-results/hkex-results/hkex-aastock/'+'data-'+ticker.zfill(5)+'-result.csv')\n",
    "    \n",
    "    # get the full path of the hang seng index average csv file\n",
    "    hsi_movement_path = os.path.join(dir_name,'train-data/hkex/hsi_movement.csv')  \n",
    "    # merge the df pandas with the hsi_average\n",
    "    df = merge_actual_label (df,hsi_movement_path)\n",
    "    # store to the csv file if the dataset is not empty\n",
    "    if (df.empty == False):\n",
    "        df.to_csv(result_path,index=False)\n",
    "\n",
    "# collect vader label for tickers in hkex    \n",
    "for tickers in hkex_df:\n",
    "     for ticker in tickers:\n",
    "            print(ticker)\n",
    "            starter_vader(ticker)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}