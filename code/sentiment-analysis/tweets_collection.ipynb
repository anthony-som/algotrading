{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install twython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "dir_name= os.getcwd()+'/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "access_token = \"\"\n",
    "access_token_secret = \"\"\n",
    "\n",
    "\n",
    "# authorization of consumer key and consumer secret \n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret) \n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True,wait_on_rate_limit_notify=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#access the data folder\n",
    "dir_name= os.getcwd()+'/data/'\n",
    "\n",
    "# access the data folder to get the list of tickers in nasdaq\n",
    "nasdaq_files=os.path.join(dir_name,'stock_ticker_datasets/nasdaq.csv')\n",
    "\n",
    "# access the data folder to get the list of tickers in nyse\n",
    "nyse_files=os.path.join(dir_name,'stock_ticker_datasets/nyse.csv')\n",
    "\n",
    "\n",
    "nasdaq=pd.read_csv(nasdaq_files) \n",
    "nyse=pd.read_csv(nyse_files)\n",
    "\n",
    "nasdaq['Symbol']=nasdaq['Symbol'].astype(str)\n",
    "nasdaq_input=nasdaq['Symbol']\n",
    "\n",
    "\n",
    "nyse['Symbol']=nyse['Symbol'].astype(str)\n",
    "nyse_input=nyse['Symbol']\n",
    "\n",
    "#chunk row size\n",
    "n = 100\n",
    "\n",
    "#split datasets into smaller sets to prevent blocked from the API\n",
    "nasdaq_df = [nasdaq_input[i:i+n] for i in range(0,nasdaq_input.shape[0],n)]\n",
    "nyse_df = [nyse_input[i:i+n] for i in range(0,nyse_input.shape[0],n)]\n",
    "\n",
    "\n",
    "nasdaq.set_index(\"Symbol\" , inplace=True)\n",
    "nyse.set_index(\"Symbol\" , inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, time\n",
    "import csv\n",
    "\n",
    "#  get data from the company's twitter timeline\n",
    "# name: twitter screen name of the ticker\n",
    "# number_of tweets: limit the number of tweets collected\n",
    "# days: limit the number of days of the tweets\n",
    "\n",
    "def returnTimelinetweets(name,number_of_tweets,days):\n",
    "\n",
    "    alltweets = []\n",
    "    user=api.get_user(name)\n",
    "    userid=user.id_str\n",
    "    # access the timeline tweets through the API\n",
    "    timeline = api.user_timeline(user_id=userid,count=number_of_tweets)\n",
    "    alltweets.extend(timeline)\n",
    "    outtweets=[]\n",
    "    for tweet in alltweets:\n",
    "        if(datetime.datetime.now()-tweet.created_at).days<=days:\n",
    "            outtweets=[tweet.created_at,tweet.text.encode(\"utf-8\")]\n",
    "\n",
    "    path=os.path.join(dir_name,'data-tweets/')\n",
    "    with open(path+'data-'+name+'-tweets.csv','a') as f:\n",
    "        writer= csv.writer(f)\n",
    "        writer.writerows(outtweets)\n",
    "            \n",
    "# get data from  the cashtag\n",
    "# name: twitter screen name of the ticker\n",
    "# days: limit the number of days of the tweets\n",
    "def get_tagtweets(name,days):\n",
    "    print(name)\n",
    "    # get the hasgtag/cashtag tweets\n",
    "    hashtags=tweepy.Cursor(api.search,q=name,lang='en',tweet_mode='extended').items(200)\n",
    "    # get the csv file of each ticker that contains the tweets\n",
    "    path=os.path.join(dir_name,'data-tweets/'+'data-'+name+'-tweets.csv')\n",
    "    print(path)\n",
    "    try:\n",
    "        with open(path,'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for status in hashtags:\n",
    "                if(datetime.datetime.now()-status.created_at).days<=days:\n",
    "                    tweet_text = status.full_text.encode(\"utf-8\")\n",
    "                    # only collect the year, month and day\n",
    "                    dates=str(status.created_at)[:10]\n",
    "                    print(dates)\n",
    "                    print(tweet_text)\n",
    "                    writer.writerow([dates,tweet_text])\n",
    "        \n",
    "            sleep(2000)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tweepy, datetime, time\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "\n",
    "# real time tweets collection using tweepy stream API\n",
    "days=1\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    \n",
    "    def __init__(self, output_file=sys.stdout,input_name=sys.stdout):\n",
    "        super(MyStreamListener,self).__init__()\n",
    "        self.output_file = output_file\n",
    "        self.max_tweets=200\n",
    "        self.tweet_count=0\n",
    "        self.input_name=input_name\n",
    "        self.days=days\n",
    "        \n",
    "    # override the on_status function\n",
    "    def on_status(self, status):\n",
    "        if(self.tweet_count==self.max_tweets):\n",
    "            return False\n",
    "        elif(datetime.datetime.now()-status.created_at).days<=self.days:\n",
    "            tweet_text = status.text\n",
    "            print(tweet_text)\n",
    "            writer = csv.writer(self.output_file)\n",
    "            \n",
    "            writer.writerow([status.created_at,status.extended_tweet['full_text'].encode(\"utf-8\")])\n",
    "            self.tweet_count+=1\n",
    "            \n",
    "        \n",
    "    def on_error(self, status_code):\n",
    "        print(status_code)\n",
    "        if status_code == 420:\n",
    "            #returning False in on_error disconnects the stream\n",
    "            \n",
    "            return False\n",
    "        \n",
    "    def on_timeout(self):\n",
    "        sys.stderr.write(\"Timeout, sleeping for 60 seconds...\\n\")\n",
    "        time.sleep(60)\n",
    "        return \n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "# loop through the list for each ticker\n",
    "\n",
    "# for firm in list:\n",
    "\n",
    "#         path=os.path.join(dir_name,'data-tweets/')\n",
    "#         with open(path+'data-'+name+'-tweets.csv','a') as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         myStreamListener = MyStreamListener(output_file=f,input_name=firm)\n",
    "#         myStream = tweepy.Stream(auth = api.auth, tweet_mode='extended',listener=myStreamListener,languages = [\"en\"])\n",
    "#         myStream.filter(track=firm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update function to update the tweets using the get_tagtweets function\n",
    "def update_tweets_all(day):\n",
    "    for list in nasdaq_df:\n",
    "        for name in list:\n",
    "            name='$'+name\n",
    "            get_tagtweets(name,day)\n",
    "\n",
    "    for list in nyse_df:\n",
    "        for name in list:\n",
    "            name='$'+name\n",
    "            get_tagtweets(name,day)\n",
    "            \n",
    "update_tweets_all(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return a pandas dataframe contains today's tweets\n",
    "# name: name of the ticker\n",
    "\n",
    "def get_today_tweets(name):\n",
    "    text=[]\n",
    "    tweets=pd.DataFrame()\n",
    "    \n",
    "    hashtags=tweepy.Cursor(api.search,q=name,lang='en',tweet_mode='extended').items(300)\n",
    "    outttags=[] \n",
    "    path=os.path.join(dir_name,'data-tweets/')\n",
    "    for status in hashtags:\n",
    "        if(datetime.datetime.now()-status.created_at).days<=1:\n",
    "            tweet_text = status.full_text.encode(\"utf-8\")\n",
    "            dates=str(status.created_at)[:10]\n",
    "            text.append(tweet_text)\n",
    "            dates.append(dates)\n",
    "    tweets['date']=dates\n",
    "    \n",
    "    ticker=[name for i in range(len(dates))]\n",
    "    tweets['ticker']=ticker\n",
    "    tweets['text']=text\n",
    "    \n",
    "    return tweets\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging all the tweets csv file in  nasdaq\n",
    "# name: name of the ticker\n",
    "def merge_nasdaq_no_label_tweets(name):\n",
    "    df = pd.DataFrame()\n",
    "    for nas in nasdaq_df:\n",
    "         for name in nas:\n",
    "            try:\n",
    "                # get the tweets file of each tciker\n",
    "                path=os.path.join(dir_name,'data-tweets/'+'data-$'+name+'-tweets.csv')\n",
    "                df_tweets = pd.read_csv(path ,names=['dates','tweets'],index_col='dates')\n",
    "                # include the sector column in the pandas dataframe\n",
    "                sector=nyse.loc[name]['Sector']\n",
    "                ticker=[name for i in range(len(df_tweets))]\n",
    "                Sector=[sector for i in range(len(df_tweets))]\n",
    "                df_tweets['ticker']=ticker\n",
    "                df_tweets['sector']=Sector\n",
    "                df=df.append(df_tweets)\n",
    "\n",
    "\n",
    "            except:\n",
    "                print('no such file exist')\n",
    "                pass\n",
    "\n",
    "            df_path=os.path.join(dir_name,'train-data/nasdaq/nasdaq_no_labelled_tweets.csv')\n",
    "            # output a csv file contains all the tweets in nasdaq\n",
    "            df.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging all the tweets csv file in  nyse\n",
    "# name: name of the ticker\n",
    "def merge_nyse_no_label_tweets(name):\n",
    "    df = pd.DataFrame()\n",
    "    for nyse in nyse_df:\n",
    "         for name in nyse:\n",
    "            try:\n",
    "                # get the tweets file of each tciker\n",
    "                path=os.path.join(dir_name,'data-tweets/'+'data-$'+name+'-tweets.csv')\n",
    "                df_tweets = pd.read_csv(path ,names=['dates','tweets'],index_col='dates')\n",
    "                 # include the sector column in the pandas dataframe\n",
    "                sector=nyse.loc[name]['Sector']\n",
    "                ticker=[name for i in range(len(df_tweets))]\n",
    "                Sector=[sector for i in range(len(df_tweets))]\n",
    "                df_tweets['ticker']=ticker\n",
    "                df_tweets['sector']=Sector\n",
    "                df=df.append(df_tweets)\n",
    "\n",
    "\n",
    "            except:\n",
    "                print('no such file exist')\n",
    "                pass\n",
    "\n",
    "            df_path=os.path.join(dir_name,'train-data/nyse/nyse_no_labelled_tweets.csv')\n",
    "            # output a csv file contains all the tweets in nyse\n",
    "            df.to_csv(df_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}